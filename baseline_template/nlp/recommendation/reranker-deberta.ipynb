{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "debertaでの学習を行う\n",
    "\n",
    "結果: MAP@25 Score: 0.1615827774568862だった\n",
    "改善している。\n",
    "\n",
    "ref: https://www.kaggle.com/code/fritzcremer/lmsys-deberta-v3-base-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T05:36:50.952526Z",
     "iopub.status.busy": "2024-09-14T05:36:50.952167Z",
     "iopub.status.idle": "2024-09-14T05:36:50.971827Z",
     "shell.execute_reply": "2024-09-14T05:36:50.971090Z"
    }
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e003-gr-ml256\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "COMPETITION_NAME = \"eedi-mining-misconceptions-in-mathematics\"\n",
    "\n",
    "DATA_PATH = \"retrieved_data\"\n",
    "ENV_PATH = \"env_file\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"{COMPETITION_NAME}/trained_models/reranker/{EXP_NAME}\"\n",
    "RETRIEVED_DATA_NAME = \"e001-train_ret25_map0.1378_recall0.4531.csv\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "UPLOAD_DATA_TO_KAGGLE = True\n",
    "WANDB = True\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 256  # TODO: 十分な長さかどうかは調査が必要\n",
    "INFERENCE_MAX_LENGTH = 256\n",
    "SEED = 42\n",
    "VALID_DATA_SIZE = 0.3\n",
    "EPOCH = 1\n",
    "LR = 2e-04\n",
    "TRAIN_BS = 8\n",
    "GRAD_ACC_NUM = 128 // TRAIN_BS  # 仮想的なバッチサイズはTRAIN_BS * GRAD_ACC_STEPとなる\n",
    "EVAL_BS = 8\n",
    "NUM_LABELS = 2  # regressionの場合は1, 2値分類の場合は2に設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T05:36:50.975923Z",
     "iopub.status.busy": "2024-09-14T05:36:50.975590Z",
     "iopub.status.idle": "2024-09-14T05:36:51.365035Z",
     "shell.execute_reply": "2024-09-14T05:36:51.363753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 13:15:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              36W / 250W |   2164MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T05:36:51.368910Z",
     "iopub.status.busy": "2024-09-14T05:36:51.368396Z",
     "iopub.status.idle": "2024-09-14T05:36:51.651026Z",
     "shell.execute_reply": "2024-09-14T05:36:51.650005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-09-14T05:36:51.655499Z",
     "iopub.status.busy": "2024-09-14T05:36:51.655118Z",
     "iopub.status.idle": "2024-09-14T05:36:52.159137Z",
     "shell.execute_reply": "2024-09-14T05:36:52.158224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/eedi-mining-misconceptions-in-mathematics/exp/reranker\n",
      "VastAi! Reranker\n",
      "../../retrieved_data\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/reranker\n",
      "VastAi! Reranker\n",
      "../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/reranker\n",
      "VastAi! Reranker\n",
      "../../env_file\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}/exp/reranker\":\n",
    "        print(\"VastAi! Reranker\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}/exp/retriever\":\n",
    "        print(\"VastAi! Retriever\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}\":\n",
    "        print(\"VastAi!\")\n",
    "        return base_path\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)\n",
    "ENV_PATH = resolve_path(ENV_PATH)\n",
    "print(ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qq polars==1.7.1\n",
    "# %pip install -qq transformers==4.44.2\n",
    "# %pip install -qq sentencepiece==0.2.0\n",
    "# %pip install -qq datasets==3.0.0\n",
    "# %pip install -qq evaluate==0.4.3\n",
    "# %pip install -qq seqeval==1.2.2\n",
    "# %pip install -qq accelerate==0.34.2\n",
    "# %pip install -qq python-dotenv==1.0.1\n",
    "# %pip install -qq wandb==0.18.0\n",
    "# %pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    ClassLabel,\n",
    ")\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "# NUM_PROC = os.cpu_count()\n",
    "NUM_PROC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "import accelerate\n",
    "\n",
    "assert transformers.__version__ == \"4.44.2\"\n",
    "assert datasets.__version__ == \"3.0.0\"\n",
    "assert evaluate.__version__ == \"0.4.3\"\n",
    "assert accelerate.__version__ == \"0.34.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{ENV_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/eedi-mining-misconceptions-in-mathematics/exp/reranker/wandb/run-20240915_131518-hn098eap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/hn098eap' target=\"_blank\">e003-gr-ml256</a></strong> to <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/hn098eap' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/hn098eap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(f\"{DATA_PATH}/{RETRIEVED_DATA_NAME}\").rename({\"target\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = pl.concat(\n",
    "        [\n",
    "            train.filter(pl.col(\"label\") == 0).sample(fraction=1.0).head(50),\n",
    "            train.filter(pl.col(\"label\") == 1).sample(fraction=1.0).head(50),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_polars(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AnswerAlphabet', 'MisconceptionId', 'MisconceptionAlphabet', 'AllText', 'PredictMisconceptionId', 'label', 'PredictMisconceptionName'],\n",
       "    num_rows: 109250\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "tokenizer.add_tokens([AddedToken(\" \" * 2, normalized=False)])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=NUM_LABELS\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AnswerAlphabet', 'MisconceptionId', 'MisconceptionAlphabet', 'AllText', 'PredictMisconceptionId', 'label', 'PredictMisconceptionName'],\n",
       "    num_rows: 109250\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a4c991174647c2bf3a188d58b64feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/109250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(examples, max_token_length: int):\n",
    "    separator = \" [SEP] \"\n",
    "\n",
    "    joined_text = (\n",
    "        examples[\"ConstructName\"]\n",
    "        + separator\n",
    "        + examples[\"SubjectName\"]\n",
    "        + separator\n",
    "        + examples[\"QuestionText\"]\n",
    "        + separator\n",
    "        + examples[\"AnswerText\"]\n",
    "        + separator  # TODO: ここもSEPで良いかどうか\n",
    "        + examples[\"PredictMisconceptionName\"]\n",
    "    )\n",
    "\n",
    "    return tokenizer(\n",
    "        joined_text,\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Use the order of operations to carry out calculations involving powers[SEP] BIDMAS[SEP] \\[\n",
      " 3 \\times 2+4-5\n",
      " \\]\n",
      " Where do the brackets need to go to make the answer equal \\( 13 \\)?[SEP] Does not need brackets[SEP] Answers order of operations questions with brackets as if the brackets are not there[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Simplify an algebraic fraction by factorising the numerator[SEP] Simplifying Algebraic Fractions[SEP] Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)[SEP] \\( m+2 \\)[SEP] Does not know how to simplify algebraic fractions[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[\"input_ids\"][50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AnswerAlphabet', 'MisconceptionId', 'MisconceptionAlphabet', 'AllText', 'PredictMisconceptionId', 'label', 'PredictMisconceptionName', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 109250\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4554a05bdfe2453bb6bbc449eae25951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/109250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d822e9117c40c59ddad84b1d071f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/109250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a1daddb39a42a7a40a92e3c348da0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/109250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_dataset.filter(\n",
    "            lambda example: example[\"QuestionId\"] % 3 != 0, num_proc=NUM_PROC\n",
    "        ),\n",
    "        \"valid\": train_dataset.filter(\n",
    "            lambda example: example[\"QuestionId\"] % 3 == 0, num_proc=NUM_PROC\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AnswerAlphabet', 'MisconceptionId', 'MisconceptionAlphabet', 'AllText', 'PredictMisconceptionId', 'label', 'PredictMisconceptionName', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 72750\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AnswerAlphabet', 'MisconceptionId', 'MisconceptionAlphabet', 'AllText', 'PredictMisconceptionId', 'label', 'PredictMisconceptionName', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 36500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds_prob = softmax(predictions, axis=-1)\n",
    "    return {\"eval_loss\": log_loss(labels, preds_prob)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケジューラの設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_NUM,\n",
    "    eval_accumulation_steps=GRAD_ACC_NUM,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=2,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='568' max='568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [568/568 30:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.086808</td>\n",
       "      <td>0.086808</td>\n",
       "      <td>97.061600</td>\n",
       "      <td>376.050000</td>\n",
       "      <td>47.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.087265</td>\n",
       "      <td>0.087265</td>\n",
       "      <td>98.225100</td>\n",
       "      <td>371.596000</td>\n",
       "      <td>46.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.092586</td>\n",
       "      <td>0.092586</td>\n",
       "      <td>97.759100</td>\n",
       "      <td>373.367000</td>\n",
       "      <td>46.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.088091</td>\n",
       "      <td>0.088091</td>\n",
       "      <td>98.410300</td>\n",
       "      <td>370.896000</td>\n",
       "      <td>46.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.087692</td>\n",
       "      <td>0.087692</td>\n",
       "      <td>97.346100</td>\n",
       "      <td>374.951000</td>\n",
       "      <td>46.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.082224</td>\n",
       "      <td>0.082224</td>\n",
       "      <td>98.412200</td>\n",
       "      <td>370.889000</td>\n",
       "      <td>46.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>165.567900</td>\n",
       "      <td>220.453000</td>\n",
       "      <td>27.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.079128</td>\n",
       "      <td>0.079128</td>\n",
       "      <td>97.444500</td>\n",
       "      <td>374.572000</td>\n",
       "      <td>46.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>96.858500</td>\n",
       "      <td>376.839000</td>\n",
       "      <td>47.110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    trainer.train()\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_OUTPUT_PATH)\n",
    "    args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  14/4563 00:00 < 01:38, 46.04 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2fd903804647dca2e7e0c42b78aefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 謎に時間がかかるので、行わない\n",
    "# TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "# valid_dataset = train_dataset.filter(\n",
    "#     lambda example: example[\"QuestionId\"] in train_valid_dataset[\"valid\"][\"QuestionId\"],\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     tokenize,\n",
    "#     batched=False,\n",
    "#     fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "valid_dataset = train_valid_dataset[\"valid\"]\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "valid_pred = softmax(trainer.predict(valid_dataset).predictions, axis=-1)\n",
    "\n",
    "np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    ")\n",
    "valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_460, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>AnswerAlphabet</th><th>Predict</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>list[i64]</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;D&quot;</td><td>[2488, 1005, … 1643]</td><td>1672</td></tr><tr><td>3</td><td>&quot;A&quot;</td><td>[618, 1180, … 2108]</td><td>1180</td></tr><tr><td>3</td><td>&quot;B&quot;</td><td>[618, 1180, … 2108]</td><td>1180</td></tr><tr><td>3</td><td>&quot;D&quot;</td><td>[1721, 618, … 2108]</td><td>1180</td></tr><tr><td>6</td><td>&quot;A&quot;</td><td>[61, 1223, … 985]</td><td>329</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1857</td><td>&quot;D&quot;</td><td>[631, 732, … 818]</td><td>461</td></tr><tr><td>1860</td><td>&quot;D&quot;</td><td>[1130, 1330, … 1818]</td><td>245</td></tr><tr><td>1863</td><td>&quot;D&quot;</td><td>[1082, 795, … 602]</td><td>1558</td></tr><tr><td>1866</td><td>&quot;C&quot;</td><td>[2306, 1971, … 516]</td><td>2306</td></tr><tr><td>1866</td><td>&quot;D&quot;</td><td>[2306, 1971, … 516]</td><td>1507</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_460, 4)\n",
       "┌────────────┬────────────────┬──────────────────────┬─────────────────┐\n",
       "│ QuestionId ┆ AnswerAlphabet ┆ Predict              ┆ MisconceptionId │\n",
       "│ ---        ┆ ---            ┆ ---                  ┆ ---             │\n",
       "│ i64        ┆ str            ┆ list[i64]            ┆ i64             │\n",
       "╞════════════╪════════════════╪══════════════════════╪═════════════════╡\n",
       "│ 0          ┆ D              ┆ [2488, 1005, … 1643] ┆ 1672            │\n",
       "│ 3          ┆ A              ┆ [618, 1180, … 2108]  ┆ 1180            │\n",
       "│ 3          ┆ B              ┆ [618, 1180, … 2108]  ┆ 1180            │\n",
       "│ 3          ┆ D              ┆ [1721, 618, … 2108]  ┆ 1180            │\n",
       "│ 6          ┆ A              ┆ [61, 1223, … 985]    ┆ 329             │\n",
       "│ …          ┆ …              ┆ …                    ┆ …               │\n",
       "│ 1857       ┆ D              ┆ [631, 732, … 818]    ┆ 461             │\n",
       "│ 1860       ┆ D              ┆ [1130, 1330, … 1818] ┆ 245             │\n",
       "│ 1863       ┆ D              ┆ [1082, 795, … 602]   ┆ 1558            │\n",
       "│ 1866       ┆ C              ┆ [2306, 1971, … 516]  ┆ 2306            │\n",
       "│ 1866       ┆ D              ┆ [2306, 1971, … 516]  ┆ 1507            │\n",
       "└────────────┴────────────────┴──────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validが30000件なのは、×25をしているから\n",
    "# 元々は、1200件*4(から、Nanが引かれた数)くらいなので、valid_data_for_cvもその程度になるはず\n",
    "valid_data_for_cv = (\n",
    "    (\n",
    "        valid_dataset.to_polars()\n",
    "        .with_columns(\n",
    "            pl.col(\"valid_pred\").map_elements(lambda x: x[1], return_dtype=pl.Float64)\n",
    "        )\n",
    "        .sort(by=[\"QuestionId_Answer\", \"valid_pred\"], descending=[False, True])\n",
    "        .group_by([\"QuestionId_Answer\"], maintain_order=True)\n",
    "        .agg(pl.col(\"PredictMisconceptionId\").alias(\"Predict\"))\n",
    "    )\n",
    "    .join(\n",
    "        valid_dataset.to_polars()[[\"QuestionId_Answer\", \"MisconceptionId\"]].unique(),\n",
    "        on=[\"QuestionId_Answer\"],\n",
    "    )\n",
    "    .sort(by=[\"QuestionId_Answer\"])\n",
    ")\n",
    "\n",
    "valid_data_for_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@25 Score: 0.1615827774568862\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1#MAP@3-Metric\n",
    "def map_at_25(predictions, labels):\n",
    "    map_sum = 0\n",
    "    for x, y in zip(predictions, labels):\n",
    "        z = [1 / i if y == j else 0 for i, j in zip(range(1, 26), x)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)\n",
    "\n",
    "\n",
    "map_at_25_score = map_at_25(\n",
    "    valid_data_for_cv[\"Predict\"], valid_data_for_cv[\"MisconceptionId\"]\n",
    ")\n",
    "print(f\"MAP@25 Score: {map_at_25_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(map_at_25_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/usr/bin/aws': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/usr/bin/aws_completer': No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 58.0M  100 58.0M    0     0  66.3M      0 --:--:-- --:--:-- --:--:-- 66.2M\n",
      "/bin/bash: line 1: unzip: command not found\n",
      "You can now run: /usr/local/bin/aws --version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/model.safetensors to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/model.safetensors An error occurred (NoSuchBucket) when calling the CreateMultipartUpload operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/tokenizer.json to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/tokenizer.json An error occurred (NoSuchBucket) when calling the CreateMultipartUpload operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/tokenizer_config.json to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/tokenizer_config.json An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/config.json to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/config.json An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/spm.model to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/spm.model An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/cv_score.txt to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/cv_score.txt An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/training_args.bin to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/training_args.bin An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/added_tokens.json to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/added_tokens.json An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/special_tokens_map.json to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/special_tokens_map.json An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: ../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256/valid_prediction.npy to s3://eedi-mining-misconceptions-in-mathematics/trained_model/e003-gr-ml256/valid_prediction.npy An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 280.7 MiB/281.0 MiB (0 Bytes/s) with 1 file(s) remaining\r"
     ]
    }
   ],
   "source": [
    "# S3へのアップロード\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://{COMPETITION_NAME}/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:e003-gr-ml256-deberta-v3-xsmall, output_dir:../../eedi-mining-misconceptions-in-mathematics/trained_models/reranker/e003-gr-ml256\n",
      "Starting upload for file config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 881/881 [00:00<00:00, 1.73kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: config.json (881B)\n",
      "Starting upload for file model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270M/270M [00:18<00:00, 15.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: model.safetensors (270MB)\n",
      "Starting upload for file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.59k/1.59k [00:00<00:00, 4.16kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tokenizer_config.json (2KB)\n",
      "Starting upload for file special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286/286 [00:00<00:00, 735B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: special_tokens_map.json (286B)\n",
      "Starting upload for file added_tokens.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55.0/55.0 [00:00<00:00, 142B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: added_tokens.json (55B)\n",
      "Starting upload for file spm.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.35M/2.35M [00:01<00:00, 1.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: spm.model (2MB)\n",
      "Starting upload for file tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.26M/8.26M [00:02<00:00, 3.14MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tokenizer.json (8MB)\n",
      "Starting upload for file training_args.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.24k/5.24k [00:00<00:00, 12.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: training_args.bin (5KB)\n",
      "Starting upload for file valid_prediction.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285k/285k [00:00<00:00, 335kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: valid_prediction.npy (285KB)\n",
      "Starting upload for file cv_score.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.0/18.0 [00:00<00:00, 46.0B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: cv_score.txt (18B)\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not DEBUG and (UPLOAD_DATA_TO_S3 or UPLOAD_DATA_TO_KAGGLE):\n",
    "#     # ローカルからは削除\n",
    "#     os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c2c6483f1d451da70425ac401ede7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.027 MB of 0.027 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/log_loss</td><td>▅▆█▆▆▃▃▂▁</td></tr><tr><td>eval/loss</td><td>▅▆█▆▆▃▃▂▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁█▁▁</td></tr><tr><td>eval/samples_per_second</td><td>██████▁██</td></tr><tr><td>eval/steps_per_second</td><td>██████▁██</td></tr><tr><td>test/log_loss</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>█▁▂▂▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▁▂▂▂▂▁▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▅▆███████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▁▂▂▂▂▂▂▂▂▁▁▁▂▂▃▁▂▂▂▁▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/log_loss</td><td>0.07746</td></tr><tr><td>eval/loss</td><td>0.07746</td></tr><tr><td>eval/runtime</td><td>96.8585</td></tr><tr><td>eval/samples_per_second</td><td>376.839</td></tr><tr><td>eval/steps_per_second</td><td>47.11</td></tr><tr><td>test/log_loss</td><td>0.07746</td></tr><tr><td>test/loss</td><td>0.07746</td></tr><tr><td>test/runtime</td><td>91.7249</td></tr><tr><td>test/samples_per_second</td><td>397.929</td></tr><tr><td>test/steps_per_second</td><td>49.747</td></tr><tr><td>total_flos</td><td>2394691250159616.0</td></tr><tr><td>train/epoch</td><td>0.99934</td></tr><tr><td>train/global_step</td><td>568</td></tr><tr><td>train/grad_norm</td><td>0.1843</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.1032</td></tr><tr><td>train_loss</td><td>0.10371</td></tr><tr><td>train_runtime</td><td>1860.1828</td></tr><tr><td>train_samples_per_second</td><td>39.109</td></tr><tr><td>train_steps_per_second</td><td>0.305</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">e003-gr-ml256</strong> at: <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/hn098eap' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/hn098eap</a><br/> View project at: <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240915_131518-hn098eap/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
